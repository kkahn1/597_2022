{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3yb9Ahzg6q"
      },
      "source": [
        "Install necessary packages. Pip has ! in front because it is a command line tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ctqjrtkNvhXQ"
      },
      "outputs": [],
      "source": [
        "#!pip install os\n",
        "#!pip install numpy\n",
        "#!pip install time\n",
        "#!pip install tensorflow-gpu\n",
        "#!pip install statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lXvGGtDzfGn"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HBFpxOh10INw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH_VJDpv0TxX"
      },
      "source": [
        "Check which version of tensorflow, set seed, get number of gpu in system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8xjdCOf1hfJ",
        "outputId": "2bf2c61d-4360-45b9-acda-5f840a6cb46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "np.random.seed(975008430)\n",
        "tf.random.set_seed(975008430)\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "613XJcWM2l_L"
      },
      "source": [
        "Import data to use in the nn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZIYfXxcusj5",
        "outputId": "59a1ea10-54ff-443f-a442-fa8647102d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uiSiY9IrsiYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79eaa4a4-eb00-4524-faba-52b62e49412b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ]
        }
      ],
      "source": [
        "# see what train_images looks like\n",
        "print(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ygC5pgVx_bPm",
        "outputId": "7522bb7c-8afe-4b9a-8c8e-4883a87ca508"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "some_digit = train_images[0]\n",
        "plt.imshow(some_digit, cmap=\"binary\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWfAHgbg80Te"
      },
      "source": [
        "See what the data look like because it will need to be scaled and/or converted to one hot encoding. From above print(tf.shape(train_images)) and print(tf.shape(test_images)) we know these are [60000, 28, 28] and [10000, 28, 28] respectively but need to be [60000, 784] and [10000, 784] respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fSOst0MI8TtO"
      },
      "outputs": [],
      "source": [
        "#normalize X\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "# reshape train and test images (input data)\n",
        "train_images = train_images.reshape(train_images.shape[0],28*28)\n",
        "test_images = test_images.reshape(test_images.shape[0],28*28)\n",
        "\n",
        "# one hot encoding of train and test labels (output)\n",
        "train_labels = tf.one_hot(train_labels,10)\n",
        "test_labels = tf.one_hot(test_labels,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLF6r8488asf"
      },
      "source": [
        "Preparing the data to use in the mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MKZmwevfDlk9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_array_ops import size\n",
        "# data\n",
        "# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "# Input layer, tensor (seen in chunk above) is shape [x, 28*28]\n",
        "size_input = 28*28\n",
        "size_first_hidden = 256\n",
        "size_second_hidden = 256\n",
        "size_output = 10\n",
        "number_of_train_examples = train_images.shape[0]\n",
        "number_of_test_examples = test_images.shape[0]\n",
        "\n",
        "# train and test sets\n",
        "\n",
        "X_train = train_images\n",
        "y_train = train_labels\n",
        "X_test = test_images\n",
        "y_test = test_labels\n",
        "\n",
        "## last 10000 training for validation\n",
        "# images\n",
        "X_train, X_validation = X_train[:-10000], X_train[-10000:]\n",
        "# labels\n",
        "y_train, y_validation = y_train[:-10000], y_train[-10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rORDPsn6tkkt"
      },
      "source": [
        "Quick look at what X_train and y_train look like to make sure nothing went wrong when reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGqfeQfPrNlb",
        "outputId": "db383444-9210-4fc5-ae02-5261e7b85e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "tf.Tensor([50000   784], shape=(2,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]], shape=(50000, 10), dtype=float32)\n",
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n",
            "tf.Tensor([10000   784], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(X_train)\n",
        "print(tf.shape(X_train))\n",
        "print(y_train)\n",
        "print(tf.shape(test_labels))\n",
        "print(tf.shape(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XhKLm8XmZRnw"
      },
      "outputs": [],
      "source": [
        "# split into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).batch(16) # although this gets redone in training...\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlE9zszPVXF"
      },
      "source": [
        "Build MLP model. this one has no regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B-4ystjrFwXb"
      },
      "outputs": [],
      "source": [
        "# define class to build mlp model\n",
        "class MLP(object):\n",
        "  def __init__(self, size_input, size_first_hidden, size_second_hidden, size_output, device=None):\n",
        "    '''\n",
        "    size_input: int, size of input layer\n",
        "    size_first_hidden: int, size of first hidden layer\n",
        "    size_second_hidden: int, size of second hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    '''\n",
        "    self.size_input, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_first_hidden, size_second_hidden, size_output, device\n",
        "\n",
        "    # initialize weights between input layer and first hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_first_hidden]))\n",
        "    # initialize weights between first hidden layer and second hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # initialize weights between second hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # initialise biases for first hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "    # initialise biases for second hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # initialise biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "\n",
        "    # define variables to be updated during backprop\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "  \n",
        "  # forward pass\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    '''\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "    \n",
        "    return self.y\n",
        "  \n",
        "  #loss function. cross entropy\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    return tf.nn.softmax_cross_entropy_with_logits(y_true_tf, y_pred_tf)\n",
        "    #scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    #temp = scce(y_true_tf, y_pred_tf).numpy()\n",
        "    #print(temp)\n",
        "    #return scce(y_true_tf, y_pred_tf).numpy()\n",
        "  \n",
        "  # backward pass\n",
        "  def backward(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    #print(type(grads))\n",
        "    #lr = 1e-4\n",
        "    #dws = grads\n",
        "    #dws_new = [i * lr for i in dws]\n",
        "    #print(type(dws[0:1]))\n",
        "    #Wt = [a_i - b_i for a_i, b_i in zip(self.variables, dws_new)]\n",
        "    #W = self.variables[0]\n",
        "    #W.assign(Wt[0])\n",
        "    #W1 = self.variables[1]\n",
        "    #W1.assign(Wt[1])\n",
        "    #W2 = self.variables[2]\n",
        "    #W2.assign(Wt[2])\n",
        "    #B = self.variables[3]\n",
        "    #B.assign(Wt[3])\n",
        "    #B1 = self.variables[4]\n",
        "    #B1.assign(Wt[4])\n",
        "    #B2 = self.variables[5]\n",
        "    #B2.assign(Wt[5])\n",
        "    #return grads\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "  \n",
        "  def vanillasgd(self, grads, lr = 1e-4):\n",
        "    '''\n",
        "    one-step of sgd to update weights\n",
        "    '''\n",
        "    print(self.variables[0])\n",
        "    print(grads[3:4])\n",
        "\n",
        "    self.variables[0] = self.variables[0] - tf.math.scalar_mul(lr,dws[0,1])\n",
        "    self.variables[1] = self.variables[1] - lr*grads[1,2]\n",
        "    self.variables[2] = self.variables[2] - lr*grads[2,3]\n",
        "    self.variables[3] = self.variables[3] - lr*grads[3,4]\n",
        "    self.variables[4] = self.variables[4] - lr*grads[4,5]\n",
        "    self.variables[5] = self.variables[5] - lr*grads[5,6]\n",
        "  \n",
        "  # compute output\n",
        "  def compute_output(self, X):\n",
        "    '''\n",
        "    obtain output tensor during forward pass\n",
        "    '''\n",
        "    # cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # remember to normalize dataset before moving forward\n",
        "    # compute values in first hidden layer\n",
        "    # softmax for multiclass classification\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # compute values in second hidden layer\n",
        "    w2hat = tf.matmul(hhat, self.W2) + self.b2\n",
        "    h2hat = tf.nn.relu(w2hat)\n",
        "    # compute output\n",
        "    output = tf.matmul(h2hat, self.W3) + self.b3\n",
        "    output_softmax = tf.nn.softmax(output)\n",
        "    return output_softmax\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xaVATaNx13x"
      },
      "source": [
        "Train model with validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY0Q2ZM9x0ca",
        "outputId": "8dd0c181-b1df-4c4f-e6bf-87d64558736d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Training Loss (CE) = 2.29429, Training Accuracy 0.827500\n",
            "Average Validation Loss (CE) = 0.47186, Validation Accuracy = 0.80500\n",
            "Number of Epoch = 2 - Average Training Loss (CE) = 2.26847, Training Accuracy 0.828750\n",
            "Average Validation Loss (CE) = 0.47241, Validation Accuracy = 0.80875\n",
            "Number of Epoch = 3 - Average Training Loss (CE) = 2.25303, Training Accuracy 0.840000\n",
            "Average Validation Loss (CE) = 0.47229, Validation Accuracy = 0.80875\n",
            "Number of Epoch = 4 - Average Training Loss (CE) = 2.23281, Training Accuracy 0.838750\n",
            "Average Validation Loss (CE) = 0.47200, Validation Accuracy = 0.79625\n",
            "Number of Epoch = 5 - Average Training Loss (CE) = 2.20796, Training Accuracy 0.850000\n",
            "Average Validation Loss (CE) = 0.47179, Validation Accuracy = 0.81625\n",
            "Number of Epoch = 6 - Average Training Loss (CE) = 2.18145, Training Accuracy 0.855000\n",
            "Average Validation Loss (CE) = 0.47154, Validation Accuracy = 0.81625\n",
            "Number of Epoch = 7 - Average Training Loss (CE) = 2.15968, Training Accuracy 0.853750\n",
            "Average Validation Loss (CE) = 0.47212, Validation Accuracy = 0.80750\n",
            "Number of Epoch = 8 - Average Training Loss (CE) = 2.14752, Training Accuracy 0.850000\n",
            "Average Validation Loss (CE) = 0.47299, Validation Accuracy = 0.80250\n",
            "Number of Epoch = 9 - Average Training Loss (CE) = 2.13620, Training Accuracy 0.855000\n",
            "Average Validation Loss (CE) = 0.47043, Validation Accuracy = 0.80250\n",
            "Number of Epoch = 10 - Average Training Loss (CE) = 2.12663, Training Accuracy 0.863750\n",
            "Average Validation Loss (CE) = 0.47245, Validation Accuracy = 0.81250\n",
            "\n",
            "Total time taken (in seconds): 311.23\n"
          ]
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "# save results into here to plot\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "val_loss_results = []\n",
        "val_accuracy_results = []\n",
        "train_mse_results = []\n",
        "val_mse_results = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results.append(accuracy_train.result())\n",
        "  val_loss_results.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results.append(accuracy_val.result())\n",
        "  train_mse_results.append(np.sum(mse_train))\n",
        "  val_mse_results.append(np.sum(mse_val))\n",
        "    #correct_prediction_val = tf.math.equal(tf.argmax(y_validation,1), tf.argmax(preds_val,1))\n",
        "    #accuracy_val = tf.reduce_mean(tf.cast(correct_prediction_val, tf.float32))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  #print('Training Accuracy = {:.5f}'.format(np.sum(accuracy_train)/ X_train.shape[0]))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "  #print('Validation Accuracy = {:.5f}'.format(np.sum(accuracy_val)/ X_train.shape[0])\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF5rXJ9muwz0"
      },
      "source": [
        "Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAYNHkkXurUS",
        "outputId": "468b28ea-f817-4589-d89b-6312824c5317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CE Loss = 0.42297, Test Accuracy = 0.88750\n"
          ]
        }
      ],
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs = []\n",
        "test_ds_trues = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test.update_state(preds, outputs)\n",
        "  accuracy_test.result().numpy()\n",
        "  test_ds_outputs.append(outputs)\n",
        "  test_ds_trues.append(y_test)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7KQzlsKMyGKU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxLFYEIjDOwO"
      },
      "source": [
        "Plotting training and validation \n",
        "Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dOSdNkXIb3aP"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "PX1vzBMADOXB",
        "outputId": "c9764c14-15e6-4ea7-ae58-2f27a543ceb2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, train_accuracy_results, label = 'Train')\n",
        "plt.plot(iterations, val_accuracy_results, label = 'Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP Without Regularization: Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig('mlp_noreg_acc.png')\n",
        "#files.download('mlp_noreg_acc.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0NcyNZEC1ecM",
        "outputId": "cc33b8e8-aec0-4211-ca44-fdddafe06838"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, train_loss_results, label = 'Train')\n",
        "plt.plot(iterations, val_loss_results, label = 'Validation')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP Without Regularization: Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig('mlp_noreg_loss.png')\n",
        "#files.download('mlp_noreg_loss.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WrgkHymKsj_x",
        "outputId": "0ad2465f-8319-41b1-a399-f8a418dee5f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, train_mse_results, label = 'Train')\n",
        "plt.plot(iterations, val_mse_results, label = 'Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP Without Regularization: MSE')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC_Jv9h9VNYV"
      },
      "source": [
        "Redoing the model with L2 regularization: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ecwsOfw38o6U"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_nn_ops import l2_loss\n",
        "# defint class to build mlp model\n",
        "class MLPl2(object):\n",
        "  def __init__(self, size_input, size_first_hidden, size_second_hidden, size_output, device=None):\n",
        "    '''\n",
        "    size_input: int, size of input layer\n",
        "    size_first_hidden: int, size of first hidden layer\n",
        "    size_second_hidden: int, size of second hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    '''\n",
        "    self.size_input, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_first_hidden, size_second_hidden, size_output, device\n",
        "\n",
        "    # initialize weights between input layer and first hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_first_hidden]))\n",
        "    # initialize weights between first hidden layer and second hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # initialize weights between second hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # initialise biases for first hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "    # initialise biases for second hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # initialise biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "\n",
        "    # define variables to be updated during backprop\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "  \n",
        "  # forward pass\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    '''\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "    \n",
        "    return self.y\n",
        "  \n",
        "  #loss function. cross entropy\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    return (tf.reduce_mean(.9 * tf.nn.softmax_cross_entropy_with_logits(y_true_tf, y_pred_tf)) +\n",
        "     .1 * tf.nn.l2_loss(self.W1) +\n",
        "     .1 * tf.nn.l2_loss(self.W2) +\n",
        "     .1 * tf.nn.l2_loss(self.W3))\n",
        "    #scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    #temp = scce(y_true_tf, y_pred_tf).numpy()\n",
        "    #print(temp)\n",
        "    #return scce(y_true_tf, y_pred_tf).numpy() \n",
        "  \n",
        "  # backward pass\n",
        "  def backward(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "  \n",
        "  def vanillasgd(self, grads, lr = 1e-4):\n",
        "    '''\n",
        "    one-step of sgd to update weights\n",
        "    '''\n",
        "    print(self.variables[0])\n",
        "    print(grads[3:4])\n",
        "\n",
        "    self.variables[0] = self.variables[0] - tf.math.scalar_mul(lr,dws[0,1])\n",
        "    self.variables[1] = self.variables[1] - lr*grads[1,2]\n",
        "    self.variables[2] = self.variables[2] - lr*grads[2,3]\n",
        "    self.variables[3] = self.variables[3] - lr*grads[3,4]\n",
        "    self.variables[4] = self.variables[4] - lr*grads[4,5]\n",
        "    self.variables[5] = self.variables[5] - lr*grads[5,6]\n",
        "  \n",
        "  # compute output\n",
        "  def compute_output(self, X):\n",
        "    '''\n",
        "    obtain output tensor during forward pass\n",
        "    '''\n",
        "    # cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # remember to normalize dataset before moving forward\n",
        "    # compute values in first hidden layer\n",
        "    # softmax for multiclass classification\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # compute values in second hidden layer\n",
        "    w2hat = tf.matmul(hhat, self.W2) + self.b2\n",
        "    h2hat = tf.nn.relu(w2hat)\n",
        "    # compute output\n",
        "    output = tf.matmul(h2hat, self.W3) + self.b3\n",
        "    output_softmax = tf.nn.softmax(output)\n",
        "    return output_softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwJoqzM_vS1W",
        "outputId": "11b3cb86-b184-47c8-d7b3-36a89bb4e9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Training Loss (CE) = 167.46934, Training Accuracy 0.810000\n",
            "Average Validation Loss (CE) = 33.28461, Validation Accuracy = 0.82250\n",
            "Number of Epoch = 2 - Average Training Loss (CE) = 165.38937, Training Accuracy 0.813750\n",
            "Average Validation Loss (CE) = 32.87123, Validation Accuracy = 0.81500\n",
            "Number of Epoch = 3 - Average Training Loss (CE) = 163.33526, Training Accuracy 0.812500\n",
            "Average Validation Loss (CE) = 32.46293, Validation Accuracy = 0.81000\n",
            "Number of Epoch = 4 - Average Training Loss (CE) = 161.30659, Training Accuracy 0.813750\n",
            "Average Validation Loss (CE) = 32.05974, Validation Accuracy = 0.81250\n",
            "Number of Epoch = 5 - Average Training Loss (CE) = 159.30313, Training Accuracy 0.810000\n",
            "Average Validation Loss (CE) = 31.66156, Validation Accuracy = 0.80875\n",
            "Number of Epoch = 6 - Average Training Loss (CE) = 157.32458, Training Accuracy 0.810000\n",
            "Average Validation Loss (CE) = 31.26835, Validation Accuracy = 0.81500\n",
            "Number of Epoch = 7 - Average Training Loss (CE) = 155.37056, Training Accuracy 0.812500\n",
            "Average Validation Loss (CE) = 30.87998, Validation Accuracy = 0.81250\n",
            "Number of Epoch = 8 - Average Training Loss (CE) = 153.44091, Training Accuracy 0.808750\n",
            "Average Validation Loss (CE) = 30.49646, Validation Accuracy = 0.80875\n",
            "Number of Epoch = 9 - Average Training Loss (CE) = 151.53521, Training Accuracy 0.815000\n",
            "Average Validation Loss (CE) = 30.11770, Validation Accuracy = 0.81250\n",
            "Number of Epoch = 10 - Average Training Loss (CE) = 149.65312, Training Accuracy 0.807500\n",
            "Average Validation Loss (CE) = 29.74362, Validation Accuracy = 0.81625\n",
            "\n",
            "Total time taken (in seconds): 321.88\n"
          ]
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "# save results into here to plot\n",
        "l2train_loss_results = []\n",
        "l2train_accuracy_results = []\n",
        "l2val_loss_results = []\n",
        "l2val_accuracy_results = []\n",
        "l2train_mse_results = []\n",
        "l2val_mse_results = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results.append(accuracy_train.result())\n",
        "  l2val_loss_results.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results.append(accuracy_val.result())\n",
        "  l2train_mse_results.append(np.sum(mse_train))\n",
        "  l2val_mse_results.append(np.sum(mse_val))\n",
        "    #correct_prediction_val = tf.math.equal(tf.argmax(y_validation,1), tf.argmax(preds_val,1))\n",
        "    #accuracy_val = tf.reduce_mean(tf.cast(correct_prediction_val, tf.float32))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  #print('Training Accuracy = {:.5f}'.format(np.sum(accuracy_train)/ X_train.shape[0]))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "  #print('Validation Accuracy = {:.5f}'.format(np.sum(accuracy_val)/ X_train.shape[0])\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "XiZkYblRw52q",
        "outputId": "f08d5827-7860-4390-f8a2-c1eef558d531"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l2train_accuracy_results, label = 'Train')\n",
        "plt.plot(iterations, l2val_accuracy_results, label = 'Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L2 Regularization: Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig('mlp_noreg_acc.png')\n",
        "#files.download('mlp_noreg_acc.png')\n",
        "\n",
        "\n",
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l2train_loss_results, label = 'Train')\n",
        "plt.plot(iterations, l2val_loss_results, label = 'Validation')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L2 Regularization: Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l2train_mse_results, label = 'Train')\n",
        "plt.plot(iterations, l2val_mse_results, label = 'Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L2 Regularization: MSE')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L07VqERfCkn",
        "outputId": "4302a346-b259-48bf-add9-0682f518e5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CE Loss = 148.71856, Test Accuracy = 0.78750\n"
          ]
        }
      ],
      "source": [
        "l2test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs = []\n",
        "l2test_ds_trues = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total = l2test_loss_total + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test.update_state(preds, outputs)\n",
        "  l2accuracy_test.result().numpy()\n",
        "  l2test_ds_outputs.append(outputs)\n",
        "  l2test_ds_trues.append(y_test)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Kp2z_VWY2S"
      },
      "source": [
        "L1 regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a5Hy8IbXWMj4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.gen_nn_ops import l2_loss\n",
        "# defint class to build mlp model\n",
        "class MLPl1(object):\n",
        "  def __init__(self, size_input, size_first_hidden, size_second_hidden, size_output, device=None):\n",
        "    '''\n",
        "    size_input: int, size of input layer\n",
        "    size_first_hidden: int, size of first hidden layer\n",
        "    size_second_hidden: int, size of second hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    '''\n",
        "    self.size_input, self.size_first_hidden, self.size_second_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_first_hidden, size_second_hidden, size_output, device\n",
        "\n",
        "    # initialize weights between input layer and first hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_first_hidden]))\n",
        "    # initialize weights between first hidden layer and second hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_first_hidden, self.size_second_hidden]))\n",
        "    # initialize weights between second hidden layer and output layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_second_hidden, self.size_output]))\n",
        "    # initialise biases for first hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_first_hidden]))\n",
        "    # initialise biases for second hidden layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_second_hidden]))\n",
        "    # initialise biases for output layer\n",
        "    self.b3 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "\n",
        "    # define variables to be updated during backprop\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.b1, self.b2, self.b3]\n",
        "  \n",
        "  # forward pass\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    '''\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "    \n",
        "    return self.y\n",
        "  \n",
        "  #loss function. cross entropy\n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    return (tf.reduce_mean(.9 * tf.nn.softmax_cross_entropy_with_logits(y_true_tf, y_pred_tf)) +\n",
        "            .1 * tf.math.reduce_sum(np.abs(self.W1)) +\n",
        "            .1 * tf.math.reduce_sum(np.abs(self.W2)) +\n",
        "            .1 * tf.math.reduce_sum(np.abs(self.W3)))\n",
        "    #scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    #temp = scce(y_true_tf, y_pred_tf).numpy()\n",
        "    #print(temp)\n",
        "    #return scce(y_true_tf, y_pred_tf).numpy() \n",
        "  \n",
        "  # backward pass\n",
        "  def backward(self, X_train, y_train):\n",
        "    '''\n",
        "    backward pass\n",
        "    '''\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "    \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "  \n",
        "  def vanillasgd(self, grads, lr = 1e-4):\n",
        "    '''\n",
        "    one-step of sgd to update weights\n",
        "    '''\n",
        "    print(self.variables[0])\n",
        "    print(grads[3:4])\n",
        "\n",
        "    self.variables[0] = self.variables[0] - tf.math.scalar_mul(lr,dws[0,1])\n",
        "    self.variables[1] = self.variables[1] - lr*grads[1,2]\n",
        "    self.variables[2] = self.variables[2] - lr*grads[2,3]\n",
        "    self.variables[3] = self.variables[3] - lr*grads[3,4]\n",
        "    self.variables[4] = self.variables[4] - lr*grads[4,5]\n",
        "    self.variables[5] = self.variables[5] - lr*grads[5,6]\n",
        "  \n",
        "  # compute output\n",
        "  def compute_output(self, X):\n",
        "    '''\n",
        "    obtain output tensor during forward pass\n",
        "    '''\n",
        "    # cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    # remember to normalize dataset before moving forward\n",
        "    # compute values in first hidden layer\n",
        "    # softmax for multiclass classification\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # compute values in second hidden layer\n",
        "    w2hat = tf.matmul(hhat, self.W2) + self.b2\n",
        "    h2hat = tf.nn.relu(w2hat)\n",
        "    # compute output\n",
        "    output = tf.matmul(h2hat, self.W3) + self.b3\n",
        "    output_softmax = tf.nn.softmax(output)\n",
        "    return output_softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT3vfCYcXJLF"
      },
      "source": [
        "Train model w/ validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1k5IFO7RXIFj",
        "outputId": "570d3f66-0ee0-44c6-f445-b151475278f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Epoch = 1 - Average Training Loss (CE) = 268.09700, Training Accuracy 0.805000\n",
            "Average Validation Loss (CE) = 53.61928, Validation Accuracy = 0.80875\n",
            "Number of Epoch = 2 - Average Training Loss (CE) = 268.09706, Training Accuracy 0.802500\n",
            "Average Validation Loss (CE) = 53.61930, Validation Accuracy = 0.79250\n",
            "Number of Epoch = 3 - Average Training Loss (CE) = 268.09704, Training Accuracy 0.802500\n",
            "Average Validation Loss (CE) = 53.61928, Validation Accuracy = 0.80625\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3e35ea580474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmlpl1_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmlpl1_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0maccuracy_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     obj.update_state = types.MethodType(\n\u001b[0;32m--> 185\u001b[0;31m         metrics_utils.update_state_wrapper(update_state_fn), obj)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mobj_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "# save results into here to plot\n",
        "l1train_loss_results = []\n",
        "l1train_accuracy_results = []\n",
        "l1val_loss_results = []\n",
        "l1val_accuracy_results = []\n",
        "l1train_mse_results = []\n",
        "l1val_mse_results = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results.append(accuracy_train.result())\n",
        "  l1val_loss_results.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results.append(accuracy_val.result())\n",
        "  l1train_mse_results.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "    #correct_prediction_val = tf.math.equal(tf.argmax(y_validation,1), tf.argmax(preds_val,1))\n",
        "    #accuracy_val = tf.reduce_mean(tf.cast(correct_prediction_val, tf.float32))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  #print('Training Accuracy = {:.5f}'.format(np.sum(accuracy_train)/ X_train.shape[0]))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "  #print('Validation Accuracy = {:.5f}'.format(np.sum(accuracy_val)/ X_train.shape[0])\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZaqyqNlfXVJ"
      },
      "outputs": [],
      "source": [
        "l1test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs = []\n",
        "l1test_ds_trues = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total = l1test_loss_total + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test.update_state(preds, outputs)\n",
        "  l1accuracy_test.result().numpy()\n",
        "  l1test_ds_outputs.append(outputs)\n",
        "  l1test_ds_trues.append(y_test)\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l1train_accuracy_results, label = 'Train')\n",
        "plt.plot(iterations, l1val_accuracy_results, label = 'Validation')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L1 Regularization: Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig('mlp_noreg_acc.png')\n",
        "#files.download('mlp_noreg_acc.png')\n",
        "\n",
        "\n",
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l1train_loss_results, label = 'Train')\n",
        "plt.plot(iterations, l1val_loss_results, label = 'Validation')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L1 Regularization: Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "iterations = list(range(NUM_EPOCHS))\n",
        "plt.plot(iterations, l1train_mse_results, label = 'Train')\n",
        "plt.plot(iterations, l1val_mse_results, label = 'Validation')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('MLP L1 Regularization: MSE')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hDQjFhkK1Lvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run each (no regularization, L1, and L2) nine more times each for a total of 10 each. Different seeds for different results each time. MLP models is already defined above so it does not need to be redefined. Retrain with validation and rerun test, resave results."
      ],
      "metadata": {
        "id": "2CzrHQXn5WZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008431)\n",
        "tf.random.set_seed(975008431)\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10"
      ],
      "metadata": {
        "id": "SEXEAs9w5nKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 2"
      ],
      "metadata": {
        "id": "CS27tcvK7bJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_2 = []\n",
        "train_accuracy_results_2 = []\n",
        "val_loss_results_2 = []\n",
        "val_accuracy_results_2 = []\n",
        "train_mse_results_2 = []\n",
        "val_mse_results_2 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_2.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_2.append(accuracy_train.result())\n",
        "  val_loss_results_2.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_2.append(accuracy_val.result())\n",
        "  train_mse_results_2.append(np.sum(mse_train))\n",
        "  val_mse_results_2.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_2 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_2 = []\n",
        "test_ds_trues_2 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_2 = test_loss_total_2 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_2 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_2.update_state(preds, outputs)\n",
        "  accuracy_test_2.result().numpy()\n",
        "  test_ds_outputs_2.append(outputs)\n",
        "  test_ds_trues_2.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "wSs45Mpq7akZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 2"
      ],
      "metadata": {
        "id": "QYVjxeleFiOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_2 = []\n",
        "l2train_accuracy_results_2 = []\n",
        "l2val_loss_results_2 = []\n",
        "l2val_accuracy_results_2 = []\n",
        "l2train_mse_results_2 = []\n",
        "l2val_mse_results_2 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_2.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_2.append(accuracy_train.result())\n",
        "  l2val_loss_results_2.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_2.append(accuracy_val.result())\n",
        "  l2train_mse_results_2.append(np.sum(mse_train))\n",
        "  l2val_mse_results_2.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_2 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_2 = []\n",
        "l2test_ds_trues_2 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_2 = l2test_loss_total_2 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_2 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_2.update_state(preds, outputs)\n",
        "  l2accuracy_test_2.result().numpy()\n",
        "  l2test_ds_outputs_2.append(outputs)\n",
        "  l2test_ds_trues_2.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "qpjGeWu1FAl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 2"
      ],
      "metadata": {
        "id": "jnmgXyqtNg0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_2 = []\n",
        "l1train_accuracy_results_2 = []\n",
        "l1val_loss_results_2 = []\n",
        "l1val_accuracy_results_2 = []\n",
        "l1train_mse_results_2 = []\n",
        "l1val_mse_results_2 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_2.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_2.append(accuracy_train.result())\n",
        "  l1val_loss_results_2.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_2.append(accuracy_val.result())\n",
        "  l1train_mse_results_2.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_2.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_2 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_2 = []\n",
        "l1test_ds_trues_2 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_2 = l1test_loss_total_2 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_2 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_2.update_state(preds, outputs)\n",
        "  l1accuracy_test_2.result().numpy()\n",
        "  l1test_ds_outputs_2.append(outputs)\n",
        "  l1test_ds_trues_2.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "XqLNNVjSNh7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008432)\n",
        "tf.random.set_seed(975008432)"
      ],
      "metadata": {
        "id": "GueGLVp-5pN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 3"
      ],
      "metadata": {
        "id": "2_CW4teaAinF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_3 = []\n",
        "train_accuracy_results_3 = []\n",
        "val_loss_results_3 = []\n",
        "val_accuracy_results_3 = []\n",
        "train_mse_results_3 = []\n",
        "val_mse_results_3 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_3.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_3.append(accuracy_train.result())\n",
        "  val_loss_results_3.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_3.append(accuracy_val.result())\n",
        "  train_mse_results_3.append(np.sum(mse_train))\n",
        "  val_mse_results_3.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_3 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_3 = []\n",
        "test_ds_trues_3 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_3 = test_loss_total_3 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_3 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_3.update_state(preds, outputs)\n",
        "  accuracy_test_3.result().numpy()\n",
        "  test_ds_outputs_3.append(outputs)\n",
        "  test_ds_trues_3.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "lkoyJ3ELAiOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 3"
      ],
      "metadata": {
        "id": "yZ18PEiAFkf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_3 = []\n",
        "l2train_accuracy_results_3 = []\n",
        "l2val_loss_results_3 = []\n",
        "l2val_accuracy_results_3 = []\n",
        "l2train_mse_results_3 = []\n",
        "l2val_mse_results_3 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_3.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_3.append(accuracy_train.result())\n",
        "  l2val_loss_results_3.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_3.append(accuracy_val.result())\n",
        "  l2train_mse_results_3.append(np.sum(mse_train))\n",
        "  l2val_mse_results_3.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_3 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_3 = []\n",
        "l2test_ds_trues_3 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_3 = l2test_loss_total_3 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_3 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_3.update_state(preds, outputs)\n",
        "  l2accuracy_test_3.result().numpy()\n",
        "  l2test_ds_outputs_3.append(outputs)\n",
        "  l2test_ds_trues_3.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "En5GbqkdFlic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 3"
      ],
      "metadata": {
        "id": "tOx8ZfP3Aw9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_3 = []\n",
        "l1train_accuracy_results_3 = []\n",
        "l1val_loss_results_3 = []\n",
        "l1val_accuracy_results_3 = []\n",
        "l1train_mse_results_3 = []\n",
        "l1val_mse_results_3 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_3.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_3.append(accuracy_train.result())\n",
        "  l1val_loss_results_3.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_3.append(accuracy_val.result())\n",
        "  l1train_mse_results_3.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_3.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_3 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_3 = []\n",
        "l1test_ds_trues_3 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_3 = l1test_loss_total_3 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_3 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_3.update_state(preds, outputs)\n",
        "  l1accuracy_test_3.result().numpy()\n",
        "  l1test_ds_outputs_3.append(outputs)\n",
        "  l1test_ds_trues_3.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "vX8VhhlJODyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008433)\n",
        "tf.random.set_seed(975008433)"
      ],
      "metadata": {
        "id": "c-vWVmPD5q2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 4"
      ],
      "metadata": {
        "id": "162DwG4rA08c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_4 = []\n",
        "train_accuracy_results_4 = []\n",
        "val_loss_results_4 = []\n",
        "val_accuracy_results_4 = []\n",
        "train_mse_results_4 = []\n",
        "val_mse_results_4 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_4.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_4.append(accuracy_train.result())\n",
        "  val_loss_results_4.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_4.append(accuracy_val.result())\n",
        "  train_mse_results_4.append(np.sum(mse_train))\n",
        "  val_mse_results_4.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_4 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_4 = []\n",
        "test_ds_trues_4 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_4 = test_loss_total_4 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_4 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_4.update_state(preds, outputs)\n",
        "  accuracy_test_4.result().numpy()\n",
        "  test_ds_outputs_4.append(outputs)\n",
        "  test_ds_trues_4.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "LeSAFBS7A0D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 4"
      ],
      "metadata": {
        "id": "DjfCKaUSGY_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_4 = []\n",
        "l2train_accuracy_results_4 = []\n",
        "l2val_loss_results_4 = []\n",
        "l2val_accuracy_results_4 = []\n",
        "l2train_mse_results_4 = []\n",
        "l2val_mse_results_4 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_4.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_4.append(accuracy_train.result())\n",
        "  l2val_loss_results_4.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_4.append(accuracy_val.result())\n",
        "  l2train_mse_results_4.append(np.sum(mse_train))\n",
        "  l2val_mse_results_4.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_4 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_4 = []\n",
        "l2test_ds_trues_4 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_4 = l2test_loss_total_4 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_4 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_4.update_state(preds, outputs)\n",
        "  l2accuracy_test_4.result().numpy()\n",
        "  l2test_ds_outputs_4.append(outputs)\n",
        "  l2test_ds_trues_4.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "SjAAEsgXGXhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 4"
      ],
      "metadata": {
        "id": "4W1Va1S-OYpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_4 = []\n",
        "l1train_accuracy_results_4 = []\n",
        "l1val_loss_results_4 = []\n",
        "l1val_accuracy_results_4 = []\n",
        "l1train_mse_results_4 = []\n",
        "l1val_mse_results_4 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_4.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_4.append(accuracy_train.result())\n",
        "  l1val_loss_results_4.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_4.append(accuracy_val.result())\n",
        "  l1train_mse_results_4.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_4.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_4 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_4 = []\n",
        "l1test_ds_trues_4 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_4 = l1test_loss_total_4 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_4 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_4.update_state(preds, outputs)\n",
        "  l1accuracy_test_4.result().numpy()\n",
        "  l1test_ds_outputs_4.append(outputs)\n",
        "  l1test_ds_trues_4.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "y-3RGGDXOZxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008434)\n",
        "tf.random.set_seed(975008434)"
      ],
      "metadata": {
        "id": "ToUHHGvV5sH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 5"
      ],
      "metadata": {
        "id": "m7Rb1pKbBGWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_5 = []\n",
        "train_accuracy_results_5 = []\n",
        "val_loss_results_5 = []\n",
        "val_accuracy_results_5 = []\n",
        "train_mse_results_5 = []\n",
        "val_mse_results_5 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_5.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_5.append(accuracy_train.result())\n",
        "  val_loss_results_5.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_5.append(accuracy_val.result())\n",
        "  train_mse_results_5.append(np.sum(mse_train))\n",
        "  val_mse_results_5.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_5 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_5 = []\n",
        "test_ds_trues_5 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_5 = test_loss_total_5 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_5 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_5.update_state(preds, outputs)\n",
        "  accuracy_test_5.result().numpy()\n",
        "  test_ds_outputs_5.append(outputs)\n",
        "  test_ds_trues_5.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "mcYC7khhBEs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 5"
      ],
      "metadata": {
        "id": "e0f6LlNTJbY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_5 = []\n",
        "l2train_accuracy_results_5 = []\n",
        "l2val_loss_results_5 = []\n",
        "l2val_accuracy_results_5 = []\n",
        "l2train_mse_results_5 = []\n",
        "l2val_mse_results_5 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_5.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_5.append(accuracy_train.result())\n",
        "  l2val_loss_results_5.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_5.append(accuracy_val.result())\n",
        "  l2train_mse_results_5.append(np.sum(mse_train))\n",
        "  l2val_mse_results_5.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_5 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_5 = []\n",
        "l2test_ds_trues_5 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_5 = l2test_loss_total_5 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_5 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_5.update_state(preds, outputs)\n",
        "  l2accuracy_test_5.result().numpy()\n",
        "  l2test_ds_outputs_5.append(outputs)\n",
        "  l2test_ds_trues_5.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "toXT4JLcJc9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 5"
      ],
      "metadata": {
        "id": "Q6iv-AOIOm1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_5 = []\n",
        "l1train_accuracy_results_5 = []\n",
        "l1val_loss_results_5 = []\n",
        "l1val_accuracy_results_5 = []\n",
        "l1train_mse_results_5 = []\n",
        "l1val_mse_results_5 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_5.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_5.append(accuracy_train.result())\n",
        "  l1val_loss_results_5.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_5.append(accuracy_val.result())\n",
        "  l1train_mse_results_5.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_5.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_5 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_5 = []\n",
        "l1test_ds_trues_5 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_5 = l1test_loss_total_5 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_5 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_5.update_state(preds, outputs)\n",
        "  l1accuracy_test_5.result().numpy()\n",
        "  l1test_ds_outputs_5.append(outputs)\n",
        "  l1test_ds_trues_5.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "RFxuL9mWOnxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008435)\n",
        "tf.random.set_seed(975008435)"
      ],
      "metadata": {
        "id": "M-KFHYl95tmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 6"
      ],
      "metadata": {
        "id": "oC3FXKlxBK_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_6 = []\n",
        "train_accuracy_results_6 = []\n",
        "val_loss_results_6 = []\n",
        "val_accuracy_results_6 = []\n",
        "train_mse_results_6 = []\n",
        "val_mse_results_6 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_6.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_6.append(accuracy_train.result())\n",
        "  val_loss_results_6.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_6.append(accuracy_val.result())\n",
        "  train_mse_results_6.append(np.sum(mse_train))\n",
        "  val_mse_results_6.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_6 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_6 = []\n",
        "test_ds_trues_6 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_6 = test_loss_total_6 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_6 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_6.update_state(preds, outputs)\n",
        "  accuracy_test_6.result().numpy()\n",
        "  test_ds_outputs_6.append(outputs)\n",
        "  test_ds_trues_6.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "LoWJA_yNB6U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 6"
      ],
      "metadata": {
        "id": "vpIpcI1HJ4Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_6 = []\n",
        "l2train_accuracy_results_6 = []\n",
        "l2val_loss_results_6 = []\n",
        "l2val_accuracy_results_6 = []\n",
        "l2train_mse_results_6 = []\n",
        "l2val_mse_results_6 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_6.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_6.append(accuracy_train.result())\n",
        "  l2val_loss_results_6.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_6.append(accuracy_val.result())\n",
        "  l2train_mse_results_6.append(np.sum(mse_train))\n",
        "  l2val_mse_results_6.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_6 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_6 = []\n",
        "l2test_ds_trues_6 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_6 = l2test_loss_total_6 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_6 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_6.update_state(preds, outputs)\n",
        "  l2accuracy_test_6.result().numpy()\n",
        "  l2test_ds_outputs_6.append(outputs)\n",
        "  l2test_ds_trues_6.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "qohI4oHKJ5ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 6"
      ],
      "metadata": {
        "id": "hY4_Ul1nO3Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_6 = []\n",
        "l1train_accuracy_results_6 = []\n",
        "l1val_loss_results_6 = []\n",
        "l1val_accuracy_results_6 = []\n",
        "l1train_mse_results_6 = []\n",
        "l1val_mse_results_6 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_6.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_6.append(accuracy_train.result())\n",
        "  l1val_loss_results_6.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_6.append(accuracy_val.result())\n",
        "  l1train_mse_results_6.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_6.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_6 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_6 = []\n",
        "l1test_ds_trues_6 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_6 = l1test_loss_total_6 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_6 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_6.update_state(preds, outputs)\n",
        "  l1accuracy_test_6.result().numpy()\n",
        "  l1test_ds_outputs_6.append(outputs)\n",
        "  l1test_ds_trues_6.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "6zTaoWBxO4D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008436)\n",
        "tf.random.set_seed(975008436)"
      ],
      "metadata": {
        "id": "dn8trMO45vTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 7"
      ],
      "metadata": {
        "id": "1zXRtPJqBL4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_7 = []\n",
        "train_accuracy_results_7 = []\n",
        "val_loss_results_7 = []\n",
        "val_accuracy_results_7 = []\n",
        "train_mse_results_7 = []\n",
        "val_mse_results_7 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_7.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_7.append(accuracy_train.result())\n",
        "  val_loss_results_7.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_7.append(accuracy_val.result())\n",
        "  train_mse_results_7.append(np.sum(mse_train))\n",
        "  val_mse_results_7.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_7 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_7 = []\n",
        "test_ds_trues_7 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_7 = test_loss_total_7 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_7 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_7.update_state(preds, outputs)\n",
        "  accuracy_test_7.result().numpy()\n",
        "  test_ds_outputs_7.append(outputs)\n",
        "  test_ds_trues_7.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "sPvEPXMiCImC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 7"
      ],
      "metadata": {
        "id": "EQeEY5w4J8nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_7 = []\n",
        "l2train_accuracy_results_7 = []\n",
        "l2val_loss_results_7 = []\n",
        "l2val_accuracy_results_7 = []\n",
        "l2train_mse_results_7 = []\n",
        "l2val_mse_results_7 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_7.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_7.append(accuracy_train.result())\n",
        "  l2val_loss_results_7.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_7.append(accuracy_val.result())\n",
        "  l2train_mse_results_7.append(np.sum(mse_train))\n",
        "  l2val_mse_results_7.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_7 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_7 = []\n",
        "l2test_ds_trues_7 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_7 = l2test_loss_total_7 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_7 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_7.update_state(preds, outputs)\n",
        "  l2accuracy_test_7.result().numpy()\n",
        "  l2test_ds_outputs_7.append(outputs)\n",
        "  l2test_ds_trues_7.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "aD-vpdYOJ-L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 7"
      ],
      "metadata": {
        "id": "CjkFReAsPJ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_7 = []\n",
        "l1train_accuracy_results_7 = []\n",
        "l1val_loss_results_7 = []\n",
        "l1val_accuracy_results_7 = []\n",
        "l1train_mse_results_7 = []\n",
        "l1val_mse_results_7 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_7.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_7.append(accuracy_train.result())\n",
        "  l1val_loss_results_7.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_7.append(accuracy_val.result())\n",
        "  l1train_mse_results_7.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_7.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_7 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_7 = []\n",
        "l1test_ds_trues_7 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_7 = l1test_loss_total_7 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_7 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_7.update_state(preds, outputs)\n",
        "  l1accuracy_test_7.result().numpy()\n",
        "  l1test_ds_outputs_7.append(outputs)\n",
        "  l1test_ds_trues_7.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "WJ3TTb8vPLyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008437)\n",
        "tf.random.set_seed(975008437)"
      ],
      "metadata": {
        "id": "SkFmBBHR5wz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 8"
      ],
      "metadata": {
        "id": "gi7ymkstBMwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_8 = []\n",
        "train_accuracy_results_8 = []\n",
        "val_loss_results_8 = []\n",
        "val_accuracy_results_8 = []\n",
        "train_mse_results_8 = []\n",
        "val_mse_results_8 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_8.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_8.append(accuracy_train.result())\n",
        "  val_loss_results_8.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_8.append(accuracy_val.result())\n",
        "  train_mse_results_8.append(np.sum(mse_train))\n",
        "  val_mse_results_8.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_8 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_8 = []\n",
        "test_ds_trues_8 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_8 = test_loss_total_8 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_8 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_8.update_state(preds, outputs)\n",
        "  accuracy_test_8.result().numpy()\n",
        "  test_ds_outputs_8.append(outputs)\n",
        "  test_ds_trues_8.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "9pb_eGZfCRYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 8"
      ],
      "metadata": {
        "id": "tjHD1DqTKFAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_8 = []\n",
        "l2train_accuracy_results_8 = []\n",
        "l2val_loss_results_8 = []\n",
        "l2val_accuracy_results_8 = []\n",
        "l2train_mse_results_8 = []\n",
        "l2val_mse_results_8 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_8.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_8.append(accuracy_train.result())\n",
        "  l2val_loss_results_8.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_8.append(accuracy_val.result())\n",
        "  l2train_mse_results_8.append(np.sum(mse_train))\n",
        "  l2val_mse_results_8.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_8 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_8 = []\n",
        "l2test_ds_trues_8 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_8 = l2test_loss_total_8 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_8 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_8.update_state(preds, outputs)\n",
        "  l2accuracy_test_8.result().numpy()\n",
        "  l2test_ds_outputs_8.append(outputs)\n",
        "  l2test_ds_trues_8.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "XNXzw1i-KGIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 8"
      ],
      "metadata": {
        "id": "1Qur8owtPXPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_8 = []\n",
        "l1train_accuracy_results_8 = []\n",
        "l1val_loss_results_8 = []\n",
        "l1val_accuracy_results_8 = []\n",
        "l1train_mse_results_8 = []\n",
        "l1val_mse_results_8 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_8.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_8.append(accuracy_train.result())\n",
        "  l1val_loss_results_8.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_8.append(accuracy_val.result())\n",
        "  l1train_mse_results_8.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_8.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_8 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_8 = []\n",
        "l1test_ds_trues_8 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_8 = l1test_loss_total_8 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_8 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_8.update_state(preds, outputs)\n",
        "  l1accuracy_test_8.result().numpy()\n",
        "  l1test_ds_outputs_8.append(outputs)\n",
        "  l1test_ds_trues_8.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "ttj-PgiJPY5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008438)\n",
        "tf.random.set_seed(975008438)"
      ],
      "metadata": {
        "id": "r_zLJ89n5yQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 9"
      ],
      "metadata": {
        "id": "vU9bBCusBNy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_9 = []\n",
        "train_accuracy_results_9 = []\n",
        "val_loss_results_9 = []\n",
        "val_accuracy_results_9 = []\n",
        "train_mse_results_9 = []\n",
        "val_mse_results_9 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_9.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_9.append(accuracy_train.result())\n",
        "  val_loss_results_9.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_9.append(accuracy_val.result())\n",
        "  train_mse_results_9.append(np.sum(mse_train))\n",
        "  val_mse_results_9.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_9 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_9 = []\n",
        "test_ds_trues_9 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_9 = test_loss_total_9 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_9 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_9.update_state(preds, outputs)\n",
        "  accuracy_test_9.result().numpy()\n",
        "  test_ds_outputs_9.append(outputs)\n",
        "  test_ds_trues_9.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "PJipkabqCQM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 9"
      ],
      "metadata": {
        "id": "Ugc0NDzvKKYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_9 = []\n",
        "l2train_accuracy_results_9 = []\n",
        "l2val_loss_results_9 = []\n",
        "l2val_accuracy_results_9 = []\n",
        "l2train_mse_results_9 = []\n",
        "l2val_mse_results_9 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_9.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_9.append(accuracy_train.result())\n",
        "  l2val_loss_results_9.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_9.append(accuracy_val.result())\n",
        "  l2train_mse_results_9.append(np.sum(mse_train))\n",
        "  l2val_mse_results_9.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_9 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_9 = []\n",
        "l2test_ds_trues_9 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_9 = l2test_loss_total_4 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_9 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_9.update_state(preds, outputs)\n",
        "  l2accuracy_test_9.result().numpy()\n",
        "  l2test_ds_outputs_9.append(outputs)\n",
        "  l2test_ds_trues_9.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "wH-VbKE8KLru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 9"
      ],
      "metadata": {
        "id": "0F2BLQV4PwfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_9 = []\n",
        "l1train_accuracy_results_9 = []\n",
        "l1val_loss_results_9 = []\n",
        "l1val_accuracy_results_9 = []\n",
        "l1train_mse_results_9 = []\n",
        "l1val_mse_results_9 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_9.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_9.append(accuracy_train.result())\n",
        "  l1val_loss_results_9.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_9.append(accuracy_val.result())\n",
        "  l1train_mse_results_9.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_9.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_9 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_9 = []\n",
        "l1test_ds_trues_9 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_9 = l1test_loss_total_9 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_9 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_9.update_state(preds, outputs)\n",
        "  l1accuracy_test_9.result().numpy()\n",
        "  l1test_ds_outputs_9.append(outputs)\n",
        "  l1test_ds_trues_9.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "I_kcyjGSPx3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(975008439)\n",
        "tf.random.set_seed(975008439)"
      ],
      "metadata": {
        "id": "iPJXyzoy5zx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No regularization 10"
      ],
      "metadata": {
        "id": "6HMEo2lOBOpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "train_loss_results_10 = []\n",
        "train_accuracy_results_10 = []\n",
        "val_loss_results_10 = []\n",
        "val_accuracy_results_10 = []\n",
        "train_mse_results_10 = []\n",
        "val_mse_results_10 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlp_on_gpu = MLP(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlp_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlp_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  train_loss_results_10.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  train_accuracy_results_10.append(accuracy_train.result())\n",
        "  val_loss_results_10.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  val_accuracy_results_10.append(accuracy_val.result())\n",
        "  train_mse_results_10.append(np.sum(mse_train))\n",
        "  val_mse_results_10.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "test_loss_total_10 = tf.Variable(0, dtype=tf.float32)\n",
        "test_ds_outputs_10 = []\n",
        "test_ds_trues_10 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total_10 = test_loss_total_10 + mlp_on_gpu.loss(preds, outputs)\n",
        "  accuracy_test_10 = tf.keras.metrics.Accuracy()\n",
        "  accuracy_test_10.update_state(preds, outputs)\n",
        "  accuracy_test_10.result().numpy()\n",
        "  test_ds_outputs_10.append(outputs)\n",
        "  test_ds_trues_10.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(test_loss_total) / X_train.shape[0], accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "0noGzQ7fCKFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 10"
      ],
      "metadata": {
        "id": "tSB7KotnKOSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here to plot\n",
        "l2train_loss_results_10 = []\n",
        "l2train_accuracy_results_10 = []\n",
        "l2val_loss_results_10 = []\n",
        "l2val_accuracy_results_10 = []\n",
        "l2train_mse_results_10 = []\n",
        "l2val_mse_results_10 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl2_on_gpu = MLPl2(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl2_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl2_on_gpu.loss(preds, outputs)\n",
        "    mlpl2_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl2_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl2_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l2train_loss_results_10.append(np.sum(loss_total_gpu)/ X_train.shape[0])\n",
        "  l2train_accuracy_results_10.append(accuracy_train.result())\n",
        "  l2val_loss_results_10.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l2val_accuracy_results_10.append(accuracy_val.result())\n",
        "  l2train_mse_results_10.append(np.sum(mse_train))\n",
        "  l2val_mse_results_10.append(np.sum(mse_val))\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu)/ X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l2test_loss_total_10 = tf.Variable(0, dtype=tf.float32)\n",
        "l2test_ds_outputs_10 = []\n",
        "l2test_ds_trues_10 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl2_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l2test_loss_total_10 = l2test_loss_total_10 + mlpl2_on_gpu.loss(preds, outputs)\n",
        "  l2accuracy_test_10 = tf.keras.metrics.Accuracy()\n",
        "  l2accuracy_test_10.update_state(preds, outputs)\n",
        "  l2accuracy_test_10.result().numpy()\n",
        "  l2test_ds_outputs_10.append(outputs)\n",
        "  l2test_ds_trues_10.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l2test_loss_total) / X_train.shape[0], l2accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "N83ONph5KP8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 10"
      ],
      "metadata": {
        "id": "qwqe5WwWQELK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results into here\n",
        "l1train_loss_results_10 = []\n",
        "l1train_accuracy_results_10 = []\n",
        "l1val_loss_results_10 = []\n",
        "l1val_accuracy_results_10 = []\n",
        "l1train_mse_results_10 = []\n",
        "l1val_mse_results_10 = []\n",
        "\n",
        "# Initialize model using GPU\n",
        "mlpl1_on_gpu = MLPl1(size_input, size_first_hidden, size_second_hidden, size_output, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlpl1_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlpl1_on_gpu.loss(preds, outputs)\n",
        "    mlpl1_on_gpu.backward(inputs, outputs)\n",
        "    accuracy_train = tf.keras.metrics.Accuracy()\n",
        "    accuracy_train.update_state(preds, outputs)\n",
        "    accuracy_train.result().numpy()\n",
        "    mse_train = tf.keras.metrics.mean_squared_error(preds, outputs)\n",
        "  val_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((X_validation, y_validation)).shuffle(25, seed=epoch*(975008430)).batch(80)\n",
        "  for input, outputs in val_ds:\n",
        "    preds_val = mlpl1_on_gpu.forward(inputs)\n",
        "    val_loss_total = val_loss_total + mlpl1_on_gpu.loss(preds_val, outputs)\n",
        "    accuracy_val = tf.keras.metrics.Accuracy()\n",
        "    accuracy_val.update_state(preds_val, outputs)\n",
        "    accuracy_val.result().numpy()\n",
        "    mse_val = tf.keras.metrics.mean_squared_error(preds_val, outputs)\n",
        "   # End epoch\n",
        "  l1train_loss_results_10.append(np.sum(loss_total_gpu) / X_train.shape[0])\n",
        "  l1train_accuracy_results_10.append(accuracy_train.result())\n",
        "  l1val_loss_results_10.append(np.sum(val_loss_total)/ X_train.shape[0])\n",
        "  l1val_accuracy_results_10.append(accuracy_val.result())\n",
        "  l1train_mse_results_10.append(np.sum(mse_train)/ X_train.shape[0])\n",
        "  l1val_mse_results_10.append(np.sum(mse_val)/ X_train.shape[0])\n",
        "  print('Number of Epoch = {} - Average Training Loss (CE) = {:.5f}, Training Accuracy {:5f}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0], accuracy_train.result().numpy()))\n",
        "  print('Average Validation Loss (CE) = {:.5f}, Validation Accuracy = {:.5f}'.format(np.sum(val_loss_total)/ X_train.shape[0], accuracy_val.result().numpy()))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "\n",
        "l1test_loss_total_10 = tf.Variable(0, dtype=tf.float32)\n",
        "l1test_ds_outputs_10 = []\n",
        "l1test_ds_trues_10 = []\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlpl1_on_gpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  l1test_loss_total_10 = l1test_loss_total_10 + mlpl1_on_gpu.loss(preds, outputs)\n",
        "  l1accuracy_test_10 = tf.keras.metrics.Accuracy()\n",
        "  l1accuracy_test_10.update_state(preds, outputs)\n",
        "  l1accuracy_test_10.result().numpy()\n",
        "  l1test_ds_outputs_10.append(outputs)\n",
        "  l1test_ds_trues_10.append(y_test)\n",
        "print('Test CE Loss = {:.5f}, Test Accuracy = {:.5f}'.format(np.sum(l1test_loss_total) / X_train.shape[0], l1accuracy_test.result().numpy()))"
      ],
      "metadata": {
        "id": "3FoiqVlqQDzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean and Variance of accuracy for test rounds for each of 10 models for each of the three types of models"
      ],
      "metadata": {
        "id": "H0ZnFeDWQXg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accs = [accuracy_test.result().numpy(), accuracy_test_2.result().numpy(), accuracy_test_3.result().numpy(), accuracy_test_4.result().numpy(), accuracy_test_5.result().numpy(), accuracy_test_6.result().numpy(), accuracy_test_7.result().numpy(), accuracy_test_8.result().numpy(), accuracy_test_9.result().numpy(), accuracy_test_10.result().numpy()]\n",
        "# issue with statistics.variance being fed numpy array\n",
        "test_accs_for_var = (0.8875, 0.85, 0.8875, 0.85, 0.825, 0.85625, 0.86875, 0.825, 0.8125, 0.84375)\n",
        "l1test_accs = [l1accuracy_test.result().numpy(), l1accuracy_test_2.result().numpy(), l1accuracy_test_3.result().numpy(), l1accuracy_test_4.result().numpy(), l1accuracy_test_5.result().numpy(), l1accuracy_test_6.result().numpy(), l1accuracy_test_7.result().numpy(), l1accuracy_test_8.result().numpy(), l1accuracy_test_9.result().numpy(), l1accuracy_test_10.result().numpy()]\n",
        "l1test_accs_for_var = (0.78125, 0.825, 0.80625, 0.79375, 0.80625, 0.825, 0.7875, 0.79375, 0.80625, 0.81875)\n",
        "l2test_accs = [l2accuracy_test.result().numpy(), l2accuracy_test_2.result().numpy(), l2accuracy_test_3.result().numpy(), l2accuracy_test_4.result().numpy(), l2accuracy_test_5.result().numpy(), l2accuracy_test_6.result().numpy(), l2accuracy_test_7.result().numpy(), l2accuracy_test_8.result().numpy(), l2accuracy_test_9.result().numpy(), l2accuracy_test_10.result().numpy()]\n",
        "l2test_accs_for_var = (0.85625, 0.8, 0.78125, 0.80625, 0.80625, 0.825, 0.8125, 0.8, 0.8, 0.84375)"
      ],
      "metadata": {
        "id": "twgWF1pShCAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_mean = statistics.mean(test_accs)\n",
        "test_acc_var = statistics.variance(test_accs_for_var)\n",
        "test_acc_stdev = statistics.stdev(test_accs_for_var)\n",
        "print(test_acc_mean)\n",
        "print(test_acc_var)\n",
        "print(test_acc_stdev)\n",
        "print(statistics.mean(l2test_accs))\n",
        "print(statistics.variance(l2test_accs_for_var))\n",
        "print(statistics.stdev(l2test_accs_for_var))\n",
        "print(statistics.mean(l1test_accs))\n",
        "print(statistics.variance(l1test_accs_for_var))\n",
        "print(statistics.stdev(l1test_accs_for_var))"
      ],
      "metadata": {
        "id": "x7mlMtiUDWy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_rounds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "plt.scatter(test_rounds, test_accs)\n",
        "plt.xlabel = 'Trial'\n",
        "plt.ylabel = 'Accuracy'\n",
        "txt=\"Mean: .8506, Variance: .0007, St. Dev.: .0256\"\n",
        "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "test_rounds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "plt.scatter(test_rounds, l2test_accs)\n",
        "plt.xlabel = 'Trial'\n",
        "plt.ylabel = 'Accuracy'\n",
        "plt.title = 'L2'\n",
        "txt=\"Mean: .8131, Variance: .0005, St. Dev.: .0225\"\n",
        "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "test_rounds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "plt.scatter(test_rounds, l1test_accs)\n",
        "plt.xlabel = 'Trial'\n",
        "plt.ylabel = 'Accuracy'\n",
        "plt.title = 'L1'\n",
        "txt=\"Mean: .8043, Variance: .0002, St. Dev.: .0153\"\n",
        "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HMikKYj3yJnN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IST597HW00010.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}